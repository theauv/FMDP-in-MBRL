# @package _group_
env: bikes
env_config:
  num_trucks: 5 #10
  action_per_day: 8
  next_day_method: random #sequential
  initial_distribution: zeros
  bikes_per_truck: 5
  start_walk_dist_max: 0.2
  end_walk_dist_max: 1000.
  trip_duration: 0.5
  past_trip_data: src/env/bikes_data/all_trips_LouVelo_merged.csv
  weather_data: src/env/bikes_data/weather_data.csv
  centroids_coord: src/env/bikes_data/LouVelo_centroids_coords.npy
  #centroids_idx: #[93,83,80,98,6,84,87,99,56,97] #Number of centroids or list of indices
  station_dependencies: null #src/env/bikes_data/factors_radius_3.npy
model_wrapper:
  _target_: src.model.dict_model_wrapper.OneDTransitionRewardModelDictSpace
  model_input_obs_key: ["bikes_distr", "time_counter"] #["bikes_distr", "day", "month", "time_counter"]
  model_input_act_key: []
  model_output_key: ["bikes_distr"]
learned_rewards: true
trial_length: ${overrides.env_config.action_per_day} #Max length episode
initial_exploration_steps: 1 #500
num_steps: 100000000 #Number of env steps before end of training
num_episodes: 365 #Number of env episodes before end of training
render_mode: human #null|rgb_array|human
model_path: null #/mnt/c/Users/theau/OneDrive/Documents/theau_epfl/12.PDM/code/HUCRL_for_FMDP/exp/pets_adapted/wandb/hypergrid/2023.10.06/154944

num_elites: 5
model_lr: 7.5e-4
model_wd: 3e-5
model_batch_size: 256
validation_ratio: 0
freq_train_model: 50
patience: 25
num_epochs_train_model: 25
dataset_size: 100000

planning_horizon: ${overrides.env_config.action_per_day}
cem_num_iters: 5
cem_elite_ratio: 0.1
cem_population_size: 350
cem_alpha: 0.1
cem_clipped_normal: false