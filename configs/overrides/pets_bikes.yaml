# @package _group_
env: bikes
env_config:
  num_trucks: 5
  action_per_day: 8
  sample_method: sequential
  initial_distribution: uniform
  bikes_per_truck: 5
  walk_distance_max: 1.
  past_trip_data: src/env/bikes_data/all_trips_LouVelo_merged.csv
  weather_data: src/env/bikes_data/weather_data.csv
  centroids_coord: src/env/bikes_data/LouVelo_centroids_coords.npy
  #centroids_idx: #[93,83,80,98,6,84,87,99,56,97]
model_wrapper:
  _target_: src.model.bikes_model_wrapper.OneDTransitionRewardModelDictSpace
  model_input_obs_key: ["bikes_dist_before_shift", "day", "month", "time_counter"]
  model_input_act_key: []
  model_output_key: ["bikes_dist_after_shift"]
learned_rewards: true #Not supported yet
trial_length: ${overrides.env_config.action_per_day} #Max length episode
num_steps: 500000 #Number of env steps before end of training
num_episodes: 400 #Number of env episodes before end of training
render_mode: human #null|rgb_array|human
model_path: null #/mnt/c/Users/theau/OneDrive/Documents/theau_epfl/12.PDM/code/HUCRL_for_FMDP/exp/pets_adapted/wandb/hypergrid/2023.10.06/154944

num_elites: 3 #5
model_lr: 7.5e-4
model_wd: 3e-5
model_batch_size: 128 #256
validation_ratio: 0
freq_train_model: 50
patience: 25
num_epochs_train_model: 1 #25

planning_horizon: ${overrides.env_config.action_per_day}
cem_num_iters: 5
cem_elite_ratio: 0.1
cem_population_size: 350
cem_alpha: 0.1
cem_clipped_normal: false