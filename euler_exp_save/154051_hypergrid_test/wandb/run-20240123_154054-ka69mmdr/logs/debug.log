2024-01-23 15:40:54,217 INFO    MainThread:68632 [wandb_setup.py:_flush():76] Current SDK version is 0.15.11
2024-01-23 15:40:54,217 INFO    MainThread:68632 [wandb_setup.py:_flush():76] Configure stats pid to 68632
2024-01-23 15:40:54,217 INFO    MainThread:68632 [wandb_setup.py:_flush():76] Loading settings from /cluster/home/tvannier/.config/wandb/settings
2024-01-23 15:40:54,217 INFO    MainThread:68632 [wandb_setup.py:_flush():76] Loading settings from /cluster/home/tvannier/HUCRL_for_FMDP/exp/wandb/hypergrid/train_model/2024.01.23/154051_hypergrid_test/wandb/settings
2024-01-23 15:40:54,217 INFO    MainThread:68632 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-01-23 15:40:54,217 INFO    MainThread:68632 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-01-23 15:40:54,217 INFO    MainThread:68632 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'run_scripts/train_model.py', 'program_abspath': '/cluster/home/tvannier/HUCRL_for_FMDP/run_scripts/train_model.py', 'program': '/cluster/home/tvannier/HUCRL_for_FMDP/run_scripts/train_model.py'}
2024-01-23 15:40:54,218 INFO    MainThread:68632 [wandb_init.py:_log_setup():528] Logging user logs to /cluster/home/tvannier/HUCRL_for_FMDP/exp/wandb/hypergrid/train_model/2024.01.23/154051_hypergrid_test/wandb/run-20240123_154054-ka69mmdr/logs/debug.log
2024-01-23 15:40:54,218 INFO    MainThread:68632 [wandb_init.py:_log_setup():529] Logging internal logs to /cluster/home/tvannier/HUCRL_for_FMDP/exp/wandb/hypergrid/train_model/2024.01.23/154051_hypergrid_test/wandb/run-20240123_154054-ka69mmdr/logs/debug-internal.log
2024-01-23 15:40:54,218 INFO    MainThread:68632 [wandb_init.py:init():568] calling init triggers
2024-01-23 15:40:54,218 INFO    MainThread:68632 [wandb_init.py:init():575] wandb.init called with sweep_config: {}
config: {'seed': 0, 'device': 'cpu', 'run_name': 'hypergrid_test', 'debug_mode': False, 'silent': False, 'dataset_folder_name': 'datasets', 'dataset_size': 100000, 'model_batch_size': 10, 'validation_ratio': 0.2, 'num_epochs_train_model': 100000, 'patience': 100000, 'learned_rewards': False, 'experiment_dir': 'wandb', 'root_dir': './exp', 'action_optimizer': {'_target_': 'mbrl.planning.CEMOptimizer', 'num_iterations': 5, 'elite_ratio': 0.1, 'population_size': 350, 'alpha': 0.1, 'lower_bound': '???', 'upper_bound': '???', 'return_mean_elites': True, 'device': 'cpu', 'clipped_normal': False}, 'algorithm': {'name': 'pets_adapted', 'agent': {'_target_': 'mbrl.planning.TrajectoryOptimizerAgent', 'action_lb': '???', 'action_ub': '???', 'planning_horizon': 15, 'optimizer_cfg': {'_target_': 'mbrl.planning.CEMOptimizer', 'num_iterations': 5, 'elite_ratio': 0.1, 'population_size': 350, 'alpha': 0.1, 'lower_bound': '???', 'upper_bound': '???', 'return_mean_elites': True, 'device': 'cpu', 'clipped_normal': False}, 'replan_freq': 1, 'verbose': False}, 'normalize': True, 'normalize_double_precision': True, 'target_is_delta': True, 'initial_exploration_steps': 400, 'freq_train_model': 50, 'learned_rewards': False, 'dataset_size': 500000, 'num_particles': 20}, 'dynamics_model': {'model_trainer': {'_target_': 'src.util.model_trainer.ModelTrainerOverriden'}, 'model': {'_target_': 'src.model.simple.Simple', 'device': 'cpu', 'num_layers': 6, 'in_size': '???', 'out_size': '???', 'hid_size': 400, 'activation_fn_cfg': {'_target_': 'torch.nn.SiLU'}}}, 'overrides': {'env': 'hypergrid', 'env_config': {'step_penalty': -1, 'grid_dim': 2, 'grid_size': 5.0, 'size_end_box': 1.0, 'step_size': 1.0, 'n_obstacles': None, 'size_obstacles': 1}, 'model_wrapper': {'_target_': 'mbrl.models.OneDTransitionRewardModel'}, 'learned_rewards': False, 'trial_length': 400, 'num_steps': 500000, 'num_episodes': 100, 'render_mode': None, 'model_path': None, 'num_elites': 5, 'model_lr': 0.00075, 'model_wd': 3e-05, 'model_batch_size': 256, 'validation_ratio': 0, 'freq_train_model': 50, 'patience': 25, 'num_epochs_train_model': 25, 'dataset_size': 500000, 'planning_horizon': 15, 'cem_num_iters': 5, 'cem_elite_ratio': 0.1, 'cem_population_size': 350, 'cem_alpha': 0.1, 'cem_clipped_normal': False}, 'experiment': {'with_tracking': True, 'plot_local': False, 'api_name': 'wandb', 'run_configs': {'project': 'hucrl_fmdp', 'group': None, 'name': 'test_model_benchmark', 'settings': None, 'tags': None}}}
2024-01-23 15:40:54,218 INFO    MainThread:68632 [wandb_init.py:init():618] starting backend
2024-01-23 15:40:54,218 INFO    MainThread:68632 [wandb_init.py:init():622] setting up manager
2024-01-23 15:40:54,220 INFO    MainThread:68632 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-01-23 15:40:54,222 INFO    MainThread:68632 [wandb_init.py:init():628] backend started and connected
2024-01-23 15:40:54,228 INFO    MainThread:68632 [wandb_init.py:init():720] updated telemetry
2024-01-23 15:40:54,254 INFO    MainThread:68632 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-01-23 15:40:54,684 INFO    MainThread:68632 [wandb_run.py:_on_init():2220] communicating current version
2024-01-23 15:40:54,829 INFO    MainThread:68632 [wandb_run.py:_on_init():2229] got version response upgrade_message: "wandb version 0.16.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-01-23 15:40:54,829 INFO    MainThread:68632 [wandb_init.py:init():804] starting run threads in backend
2024-01-23 15:40:54,975 INFO    MainThread:68632 [wandb_run.py:_console_start():2199] atexit reg
2024-01-23 15:40:54,975 INFO    MainThread:68632 [wandb_run.py:_redirect():2054] redirect: wrap_raw
2024-01-23 15:40:54,976 INFO    MainThread:68632 [wandb_run.py:_redirect():2119] Wrapping output streams.
2024-01-23 15:40:54,976 INFO    MainThread:68632 [wandb_run.py:_redirect():2144] Redirects installed.
2024-01-23 15:40:54,978 INFO    MainThread:68632 [wandb_init.py:init():845] run started, returning control to user process
