seed: 0
device: cpu
log_frequency_agent: 1000
save_video: false
debug_mode: false
experiment_dir: ${experiment.api_name}
root_dir: ./exp
algorithm:
  name: pets_adapted
  agent:
    _target_: mbrl.planning.TrajectoryOptimizerAgent
    action_lb: ???
    action_ub: ???
    planning_horizon: ${overrides.planning_horizon}
    optimizer_cfg: ${action_optimizer}
    replan_freq: 1
    verbose: ${debug_mode}
  normalize: false
  rescale_input: true
  normalize_double_precision: true
  target_is_delta: true
  initial_exploration_steps: ${overrides.trial_length}
  freq_train_model: ${overrides.freq_train_model}
  learned_rewards: ${overrides.learned_rewards}
  dataset_size: ${overrides.dataset_size}
  num_particles: 20
dynamics_model:
  model_trainer:
    _target_: src.util.model_trainer.ModelTrainerOverriden
  model:
    _target_: src.model.gaussian_process.MultiOutputGP
    device: ${device}
    in_size: ???
    out_size: ???
    mean: Linear
    kernel: Matern
    scale_kernel: true
  batch_size: ${overrides.dataset_size}
  model_lr: 0.01
  model_wd: 0.0
overrides:
  env: bikes
  env_config:
    num_trucks: 1
    action_per_day: 4
    next_day_method: random
    initial_distribution: zeros
    bikes_per_truck: 5
    fix_bikes_per_truck: true
    start_walk_dist_max: 0.2
    end_walk_dist_max: 1000.0
    trip_duration: 0.5
    past_trip_data: null
    weather_data: null
    centroids_coord: src/env/bikes_data/5_centroids/5_centroids.npy
    station_dependencies: src/env/bikes_data/5_centroids/factors_radius_4.npy
  model_wrapper:
    _target_: src.model.dict_model_wrapper.OneDTransitionRewardModelDictSpace
    model_input_obs_key:
    - bikes_distr
    - time_counter
    model_input_act_key: []
    model_output_key:
    - bikes_distr
  learned_rewards: true
  trial_length: ${overrides.env_config.action_per_day}
  initial_exploration_steps: 50
  num_steps: 100000000
  num_episodes: 10000
  render_mode: human
  model_path: null
  model_batch_size: 256
  validation_ratio: 0
  freq_train_model: 20
  patience: ${overrides.num_epochs_train_model}
  num_epochs_train_model: 10
  dataset_size: 100000
  planning_horizon: ${overrides.env_config.action_per_day}
  cem_num_iters: 20
  cem_elite_ratio: 0.1
  cem_population_size: 350
  cem_alpha: 0.1
  cem_clipped_normal: false
action_optimizer:
  _target_: mbrl.planning.CEMOptimizer
  num_iterations: ${overrides.cem_num_iters}
  elite_ratio: ${overrides.cem_elite_ratio}
  population_size: ${overrides.cem_population_size}
  alpha: ${overrides.cem_alpha}
  lower_bound: ???
  upper_bound: ???
  return_mean_elites: true
  device: ${device}
  clipped_normal: ${overrides.cem_clipped_normal}
experiment:
  with_tracking: true
  plot_local: false
  api_name: wandb
  run_configs:
    project: hucrl_fmdp
    group: euler_multistep_artificial_5centroid
    name: test_gaussian_process_lr_0.01
    settings: null
    tags: null
